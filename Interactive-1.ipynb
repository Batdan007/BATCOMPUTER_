{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.13.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f5e28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# collect_emails.py - FIXED VERSION\n",
    "import imaplib\n",
    "import email\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "def chunk_text(text, max_length=1000):\n",
    "    \"\"\"\n",
    "    Improved text chunking with better error handling\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Normalize Unicode characters to the closest ASCII representation\n",
    "    try:\n",
    "        text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Unicode normalization failed: {e}\")\n",
    "        # Fallback to original text if normalization fails\n",
    "        pass\n",
    "\n",
    "    # Remove sequences of '>' used in email threads\n",
    "    text = re.sub(r'\\s*(?:>\\s*){2,}', ' ', text)\n",
    "\n",
    "    # Remove sequences of dashes, underscores, or non-breaking spaces\n",
    "    text = re.sub(r'-{3,}', ' ', text)\n",
    "    text = re.sub(r'_{3,}', ' ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)  # Collapse multiple spaces into one\n",
    "\n",
    "    # Replace URLs with a single space, or remove them\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Normalize whitespace to single spaces, strip leading/trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Split text into sentences while preserving punctuation\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) + 1 < max_length:\n",
    "            current_chunk += (sentence + \" \").strip()\n",
    "        else:\n",
    "            if current_chunk.strip():  # Only add non-empty chunks\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \" \"\n",
    "    \n",
    "    if current_chunk.strip():  # Add final chunk if not empty\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def save_chunks_to_vault(chunks):\n",
    "    \"\"\"\n",
    "    Save chunks with better error handling and file management\n",
    "    \"\"\"\n",
    "    if not chunks:\n",
    "        return\n",
    "    \n",
    "    vault_path = \"vault.txt\"\n",
    "    try:\n",
    "        with open(vault_path, \"a\", encoding=\"utf-8\") as vault_file:\n",
    "            for chunk in chunks:\n",
    "                if chunk.strip():  # Only write non-empty chunks\n",
    "                    vault_file.write(chunk.strip() + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving chunks to vault: {e}\")\n",
    "\n",
    "def get_text_from_html(html_content):\n",
    "    \"\"\"\n",
    "    Extract text from HTML with error handling\n",
    "    \"\"\"\n",
    "    if not html_content:\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'lxml')\n",
    "        return soup.get_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing HTML content: {e}\")\n",
    "        # Fallback to basic text extraction\n",
    "        return re.sub(r'<[^>]+>', '', html_content)\n",
    "\n",
    "def get_charset_with_fallback(part):\n",
    "    \"\"\"\n",
    "    Get character encoding with fallbacks\n",
    "    \"\"\"\n",
    "    charset = part.get_content_charset()\n",
    "    if charset:\n",
    "        return charset\n",
    "    \n",
    "    # Common fallbacks\n",
    "    fallback_charsets = ['utf-8', 'iso-8859-1', 'windows-1252', 'ascii']\n",
    "    return fallback_charsets\n",
    "\n",
    "def decode_content_safely(content, charsets):\n",
    "    \"\"\"\n",
    "    Safely decode content with multiple charset attempts\n",
    "    \"\"\"\n",
    "    if isinstance(charsets, str):\n",
    "        charsets = [charsets]\n",
    "    \n",
    "    for charset in charsets:\n",
    "        try:\n",
    "            return content.decode(charset)\n",
    "        except (UnicodeDecodeError, LookupError) as e:\n",
    "            print(f\"Failed to decode with {charset}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Final fallback - decode with errors ignored\n",
    "    try:\n",
    "        return content.decode('utf-8', errors='ignore')\n",
    "    except Exception:\n",
    "        return str(content)  # Last resort\n",
    "\n",
    "def save_plain_text_content(email_bytes, email_id):\n",
    "    \"\"\"\n",
    "    Extract and save email content with improved error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        msg = BytesParser(policy=policy.default).parsebytes(email_bytes)\n",
    "        text_content = \"\"\n",
    "        \n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                try:\n",
    "                    content_type = part.get_content_type()\n",
    "                    if content_type == 'text/plain':\n",
    "                        payload = part.get_payload(decode=True)\n",
    "                        if payload:\n",
    "                            charsets = get_charset_with_fallback(part)\n",
    "                            text_content += decode_content_safely(payload, charsets)\n",
    "                    elif content_type == 'text/html':\n",
    "                        payload = part.get_payload(decode=True)\n",
    "                        if payload:\n",
    "                            charsets = get_charset_with_fallback(part)\n",
    "                            html_content = decode_content_safely(payload, charsets)\n",
    "                            text_content += get_text_from_html(html_content)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing email part: {e}\")\n",
    "                    continue\n",
    "        else:\n",
    "            try:\n",
    "                content_type = msg.get_content_type()\n",
    "                payload = msg.get_payload(decode=True)\n",
    "                if payload:\n",
    "                    charsets = get_charset_with_fallback(msg)\n",
    "                    if content_type == 'text/plain':\n",
    "                        text_content = decode_content_safely(payload, charsets)\n",
    "                    elif content_type == 'text/html':\n",
    "                        html_content = decode_content_safely(payload, charsets)\n",
    "                        text_content = get_text_from_html(html_content)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing single-part email: {e}\")\n",
    "\n",
    "        if text_content.strip():  # Only process non-empty content\n",
    "            chunks = chunk_text(text_content)\n",
    "            save_chunks_to_vault(chunks)\n",
    "            return text_content\n",
    "        else:\n",
    "            print(f\"No text content found in email ID: {email_id}\")\n",
    "            return \"\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing email ID {email_id}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def search_and_process_emails(imap_client, email_source, search_keyword, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Search and process emails with better error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build search criteria more carefully\n",
    "        search_parts = []\n",
    "        \n",
    "        if start_date and end_date:\n",
    "            search_parts.append(f'(SINCE \"{start_date}\" BEFORE \"{end_date}\")')\n",
    "        \n",
    "        if search_keyword:\n",
    "            # Escape quotes in keyword\n",
    "            escaped_keyword = search_keyword.replace('\"', '\\\\\"')\n",
    "            search_parts.append(f'BODY \"{escaped_keyword}\"')\n",
    "        \n",
    "        if search_parts:\n",
    "            search_criteria = ' '.join(search_parts)\n",
    "        else:\n",
    "            search_criteria = 'ALL'\n",
    "\n",
    "        print(f\"Using search criteria for {email_source}: {search_criteria}\")\n",
    "        \n",
    "        typ, data = imap_client.search(None, search_criteria)\n",
    "        if typ == 'OK' and data[0]:\n",
    "            email_ids = data[0].split()\n",
    "            print(f\"Found {len(email_ids)} emails matching criteria in {email_source}.\")\n",
    "\n",
    "            success_count = 0\n",
    "            for num in email_ids:\n",
    "                try:\n",
    "                    typ, email_data = imap_client.fetch(num, '(RFC822)')\n",
    "                    if typ == 'OK' and email_data[0]:\n",
    "                        email_id = num.decode('utf-8')\n",
    "                        print(f\"Processing email ID: {email_id} from {email_source}\")\n",
    "                        result = save_plain_text_content(email_data[0][1], email_id)\n",
    "                        if result:\n",
    "                            success_count += 1\n",
    "                    else:\n",
    "                        print(f\"Failed to fetch email ID: {num.decode('utf-8')} from {email_source}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing email {num}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Successfully processed {success_count}/{len(email_ids)} emails from {email_source}\")\n",
    "        else:\n",
    "            print(f\"No emails found matching criteria in {email_source}.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error searching emails in {email_source}: {e}\")\n",
    "\n",
    "def connect_to_email_server(server, username, password, email_source):\n",
    "    \"\"\"\n",
    "    Connect to email server with error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not username or not password:\n",
    "            print(f\"Missing credentials for {email_source}. Skipping...\")\n",
    "            return None\n",
    "        \n",
    "        imap_client = imaplib.IMAP4_SSL(server)\n",
    "        imap_client.login(username, password)\n",
    "        imap_client.select('inbox')\n",
    "        print(f\"Successfully connected to {email_source}\")\n",
    "        return imap_client\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to {email_source}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Search and process emails based on optional keyword and date range.\")\n",
    "    parser.add_argument(\"--keyword\", help=\"The keyword to search for in the email bodies.\", default=\"\")\n",
    "    parser.add_argument(\"--startdate\", help=\"Start date in DD.MM.YYYY format.\", required=False)\n",
    "    parser.add_argument(\"--enddate\", help=\"End date in DD.MM.YYYY format.\", required=False)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "\n",
    "    # Check if both start and end dates are provided and valid\n",
    "    if args.startdate and args.enddate:\n",
    "        try:\n",
    "            start_date = datetime.strptime(args.startdate, \"%d.%m.%Y\").strftime(\"%d-%b-%Y\")\n",
    "            end_date = datetime.strptime(args.enddate, \"%d.%m.%Y\").strftime(\"%d-%b-%Y\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: Date format is incorrect. Please use DD.MM.YYYY format. Details: {e}\")\n",
    "            return\n",
    "    elif args.startdate or args.enddate:\n",
    "        print(\"Both start date and end date must be provided together.\")\n",
    "        return\n",
    "\n",
    "    # Retrieve email credentials from environment variables\n",
    "    gmail_username = os.getenv('GMAIL_USERNAME')\n",
    "    gmail_password = os.getenv('GMAIL_PASSWORD')\n",
    "    outlook_username = os.getenv('OUTLOOK_USERNAME')\n",
    "    outlook_password = os.getenv('OUTLOOK_PASSWORD')\n",
    "\n",
    "    connections = []\n",
    "    \n",
    "    # Connect to Gmail's IMAP server\n",
    "    gmail_client = connect_to_email_server('imap.gmail.com', gmail_username, gmail_password, \"Gmail\")\n",
    "    if gmail_client:\n",
    "        connections.append((gmail_client, \"Gmail\"))\n",
    "\n",
    "    # Connect to Outlook IMAP server\n",
    "    outlook_client = connect_to_email_server('imap-mail.outlook.com', outlook_username, outlook_password, \"Outlook\")\n",
    "    if outlook_client:\n",
    "        connections.append((outlook_client, \"Outlook\"))\n",
    "\n",
    "    if not connections:\n",
    "        print(\"No email connections established. Please check your credentials.\")\n",
    "        return\n",
    "\n",
    "    # Search and process emails from all connected services\n",
    "    for client, source in connections:\n",
    "        try:\n",
    "            search_and_process_emails(client, source, args.keyword, start_date, end_date)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {source} emails: {e}\")\n",
    "        finally:\n",
    "            try:\n",
    "                client.logout()\n",
    "            except Exception as e:\n",
    "                print(f\"Error closing {source} connection: {e}\")\n",
    "\n",
    "    print(\"Email processing completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# emailrag2.py - FIXED VERSION\n",
    "import torch\n",
    "import ollama\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "PINK = '\\033[95m'\n",
    "CYAN = '\\033[96m'\n",
    "YELLOW = '\\033[93m'\n",
    "NEON_GREEN = '\\033[92m'\n",
    "RESET_COLOR = '\\033[0m'\n",
    "\n",
    "def load_config(config_file):\n",
    "    \"\"\"Load configuration with error handling\"\"\"\n",
    "    print(\"Loading configuration...\")\n",
    "    try:\n",
    "        with open(config_file, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            \n",
    "        # Validate required config keys\n",
    "        required_keys = ['vault_file', 'embeddings_file', 'ollama_model', 'top_k', 'system_message']\n",
    "        for key in required_keys:\n",
    "            if key not in config:\n",
    "                print(f\"Missing required configuration key: {key}\")\n",
    "                exit(1)\n",
    "                \n",
    "        return config\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Configuration file '{config_file}' not found.\")\n",
    "        exit(1)\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Error parsing YAML configuration: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "def open_file(filepath):\n",
    "    \"\"\"Open file with error handling\"\"\"\n",
    "    print(f\"Opening file: {filepath}\")\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "            return infile.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filepath}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{filepath}': {e}\")\n",
    "        return None\n",
    "\n",
    "def load_or_generate_embeddings(vault_content, embeddings_file):\n",
    "    \"\"\"Load or generate embeddings with better error handling\"\"\"\n",
    "    if os.path.exists(embeddings_file):\n",
    "        print(f\"Loading embeddings from '{embeddings_file}'...\")\n",
    "        try:\n",
    "            with open(embeddings_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                embeddings_data = json.load(file)\n",
    "                if embeddings_data:\n",
    "                    return torch.tensor(embeddings_data)\n",
    "                else:\n",
    "                    print(\"Embeddings file is empty. Generating new embeddings...\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Invalid JSON format in embeddings file '{embeddings_file}': {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embeddings: {e}\")\n",
    "    \n",
    "    print(\"Generating new embeddings...\")\n",
    "    embeddings = generate_embeddings(vault_content)\n",
    "    if embeddings:\n",
    "        save_embeddings(embeddings, embeddings_file)\n",
    "        return torch.tensor(embeddings)\n",
    "    else:\n",
    "        return torch.empty(0)\n",
    "\n",
    "def generate_embeddings(vault_content):\n",
    "    \"\"\"Generate embeddings with error handling\"\"\"\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = []\n",
    "    \n",
    "    if not vault_content:\n",
    "        print(\"No vault content to generate embeddings for.\")\n",
    "        return embeddings\n",
    "    \n",
    "    for i, content in enumerate(vault_content):\n",
    "        if not content.strip():  # Skip empty content\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            response = ollama.embeddings(model='mxbai-embed-large', prompt=content.strip())\n",
    "            if 'embedding' in response:\n",
    "                embeddings.append(response[\"embedding\"])\n",
    "            else:\n",
    "                print(f\"No embedding returned for content item {i}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embedding for content item {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Generated {len(embeddings)} embeddings from {len(vault_content)} content items\")\n",
    "    return embeddings\n",
    "\n",
    "def save_embeddings(embeddings, embeddings_file):\n",
    "    \"\"\"Save embeddings with error handling\"\"\"\n",
    "    print(f\"Saving embeddings to '{embeddings_file}'...\")\n",
    "    try:\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(os.path.dirname(embeddings_file) if os.path.dirname(embeddings_file) else '.', exist_ok=True)\n",
    "        \n",
    "        with open(embeddings_file, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(embeddings, file)\n",
    "        print(f\"Successfully saved {len(embeddings)} embeddings\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving embeddings: {e}\")\n",
    "\n",
    "def get_relevant_context(rewritten_input, vault_embeddings, vault_content, top_k):\n",
    "    \"\"\"Get relevant context with improved error handling\"\"\"\n",
    "    print(\"Retrieving relevant context...\")\n",
    "    \n",
    "    if not rewritten_input or not rewritten_input.strip():\n",
    "        print(\"Empty input provided\")\n",
    "        return []\n",
    "        \n",
    "    if vault_embeddings.nelement() == 0:\n",
    "        print(\"No embeddings available\")\n",
    "        return []\n",
    "    \n",
    "    if not vault_content:\n",
    "        print(\"No vault content available\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        input_embedding_response = ollama.embeddings(model='mxbai-embed-large', prompt=rewritten_input)\n",
    "        if 'embedding' not in input_embedding_response:\n",
    "            print(\"Failed to generate input embedding\")\n",
    "            return []\n",
    "            \n",
    "        input_embedding = torch.tensor(input_embedding_response[\"embedding\"]).unsqueeze(0)\n",
    "        cos_scores = torch.cosine_similarity(input_embedding, vault_embeddings)\n",
    "        \n",
    "        top_k = min(top_k, len(cos_scores))\n",
    "        if top_k <= 0:\n",
    "            return []\n",
    "            \n",
    "        top_indices = torch.topk(cos_scores, k=top_k)[1].tolist()\n",
    "        relevant_context = []\n",
    "        \n",
    "        for idx in top_indices:\n",
    "            if idx < len(vault_content) and vault_content[idx].strip():\n",
    "                relevant_context.append(vault_content[idx].strip())\n",
    "        \n",
    "        return relevant_context\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting relevant context: {e}\")\n",
    "        return []\n",
    "\n",
    "def ollama_chat(user_input, system_message, vault_embeddings, vault_content, ollama_model, conversation_history, top_k, client):\n",
    "    \"\"\"Chat function with improved error handling\"\"\"\n",
    "    try:\n",
    "        relevant_context = get_relevant_context(user_input, vault_embeddings, vault_content, top_k)\n",
    "        \n",
    "        if relevant_context:\n",
    "            context_str = \"\\n\".join(relevant_context)\n",
    "            print(\"Context Pulled from Documents: \\n\\n\" + CYAN + context_str + RESET_COLOR)\n",
    "        else:\n",
    "            print(\"No relevant context found.\")\n",
    "\n",
    "        user_input_with_context = user_input\n",
    "        if relevant_context:\n",
    "            user_input_with_context = context_str + \"\\n\\n\" + user_input\n",
    "\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_input_with_context})\n",
    "        messages = [{\"role\": \"system\", \"content\": system_message}] + conversation_history\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=ollama_model,\n",
    "            messages=messages,\n",
    "            max_tokens=2000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        assistant_response = response.choices[0].message.content\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        \n",
    "        return assistant_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error in Ollama chat: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Ollama Chat with Email RAG\")\n",
    "    parser.add_argument(\"--config\", default=\"config.yaml\", help=\"Path to the configuration file\")\n",
    "    parser.add_argument(\"--clear-cache\", action=\"store_true\", help=\"Clear the embeddings cache\")\n",
    "    parser.add_argument(\"--model\", help=\"Model to use for embeddings and responses\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    try:\n",
    "        config = load_config(args.config)\n",
    "\n",
    "        if args.clear_cache and os.path.exists(config[\"embeddings_file\"]):\n",
    "            print(f\"Clearing embeddings cache at '{config['embeddings_file']}'...\")\n",
    "            os.remove(config[\"embeddings_file\"])\n",
    "\n",
    "        if args.model:\n",
    "            config[\"ollama_model\"] = args.model\n",
    "\n",
    "        vault_content = []\n",
    "        if os.path.exists(config[\"vault_file\"]):\n",
    "            print(f\"Loading content from vault '{config['vault_file']}'...\")\n",
    "            with open(config[\"vault_file\"], \"r\", encoding='utf-8') as vault_file:\n",
    "                vault_content = [line for line in vault_file.readlines() if line.strip()]\n",
    "        else:\n",
    "            print(f\"Vault file '{config['vault_file']}' not found. Please run collect_emails.py first.\")\n",
    "            return\n",
    "\n",
    "        if not vault_content:\n",
    "            print(\"No content found in vault file. Please run collect_emails.py first.\")\n",
    "            return\n",
    "\n",
    "        vault_embeddings_tensor = load_or_generate_embeddings(vault_content, config[\"embeddings_file\"])\n",
    "\n",
    "        # Initialize OpenAI client for Ollama\n",
    "        try:\n",
    "            client = OpenAI(\n",
    "                base_url=config[\"ollama_api\"][\"base_url\"],\n",
    "                api_key=config[\"ollama_api\"][\"api_key\"]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing Ollama client: {e}\")\n",
    "            print(\"Please ensure Ollama is running on the specified base_url\")\n",
    "            return\n",
    "\n",
    "        conversation_history = []\n",
    "        system_message = config[\"system_message\"]\n",
    "\n",
    "        print(\"Email RAG system initialized successfully!\")\n",
    "        print(\"You can now ask questions about your emails.\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(YELLOW + \"Ask a question about your emails (or type 'quit' to exit): \" + RESET_COLOR)\n",
    "                if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                    break\n",
    "                \n",
    "                if not user_input.strip():\n",
    "                    print(\"Please enter a valid question.\")\n",
    "                    continue\n",
    "                    \n",
    "                response = ollama_chat(\n",
    "                    user_input, \n",
    "                    system_message, \n",
    "                    vault_embeddings_tensor, \n",
    "                    vault_content, \n",
    "                    config[\"ollama_model\"], \n",
    "                    conversation_history, \n",
    "                    config[\"top_k\"], \n",
    "                    client\n",
    "                )\n",
    "                print(NEON_GREEN + \"Response: \\n\\n\" + response + RESET_COLOR)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nExiting...\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error during conversation: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
